{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shake/colab-Llama-2-ipynb/blob/main/huggingface/hg_01_get_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 小白入门HuggingFace\n",
        "\n",
        "## 01 概念扫盲\n",
        "\n",
        "- Transformers\n",
        "    \n",
        "    `Transformers` 是 `Huggingface` 开源的基于 transformer 模型结构提供的预训练语言库，支持 `Pytorch`，`Tensorflow2.0`。使用者可以快速地进行模型调用，并且支持模型的进一步的训练和微调。\n",
        "\n",
        "- Tokenizer\n",
        "    \n",
        "    `Transformers` 库中的重要模块，用于将文本数据切分成单独的标记（tokens），并进行编码，以便交给模型进行处理。在 `NLP` 中，将文本转换成标记是一个重要的预处理步骤，不同的模型可能使用不同的 `Tokenizer` 来处理文本数据，例如 `BERTTokenizer`、`GPT2Tokenizer` 等。\n",
        "- Pipeline\n",
        "    \n",
        "    `HuggingFace` 提供的接口，使得在 `Transformers` 库中使用预训练模型更加简单。通过 `Pipeline`，您可以轻松地对输入文本进行处理并获取模型的输出结果，而不需要手动进行繁琐的**预处理**和**后处理**步骤。例如，您可以使用 TextClassificationPipeline 对输入文本进行分类，或使用 TextGenerationPipeline 生成一段文本。\n",
        "\n"
      ],
      "metadata": {
        "id": "CjdVcOQpVD9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72QCk5LhKxLI",
        "outputId": "8f7900d9-532f-4989-9f81-92eafcf863eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"facebook/bart-large-cnn\""
      ],
      "metadata": {
        "id": "2StFJj7BMMg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = \"\"\"\n",
        "The explosion of consumer-facing tools that offer generative AI has created plenty of debate: These tools promise to transform the ways in which we live and work while also raising fundamental questions about how we can adapt to a world in which they're extensively used for just about anything.\n",
        "\n",
        "As with any new technology riding a wave of initial popularity and interest, it pays to be careful in the way you use these AI generators and bots—in particular, in how much privacy and security you're giving up in return for being able to use them.\n",
        "\n",
        "It's worth putting some guardrails in place right at the start of your journey with these tools, or indeed deciding not to deal with them at all, based on how your data is collected and processed. Here's what you need to look out for and the ways in which you can get some control back.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1_cwbFm1MTKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 利用pipeline使用模型"
      ],
      "metadata": {
        "id": "i-rvecWiMTuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipeline = pipeline(\"summarization\", model=model_id)"
      ],
      "metadata": {
        "id": "KfGLojEYcm1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwiVdpRXLjuf",
        "outputId": "d88bc48d-4eae-4ccb-de78-bdeed7dd82a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \"The explosion of consumer-facing tools that offer generative AI has created plenty of debate. It's worth putting some guardrails in place right at the start of your journey with these tools. Here's what you need to look out for and the ways in which you can get some control back.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}